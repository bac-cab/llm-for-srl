{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grisha/virtual_env/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "%load_ext rich\n",
    "import datasets as ds\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"role-mapping.json\", 'r') as f:\n",
    "    role_mapping = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "model = spacy.load(\"ru_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_lemmatize(word):\n",
    "    return next(iter(model(word))).lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds.load_dataset(\"Rexhaif/framebank_srl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remapper(example):\n",
    "    return {\n",
    "        'text_fixed': \" \".join(example['tokens']) if 'tokens' in example else example['text'] if 'text' in example else example['text_fixed']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(remapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tagged(example):\n",
    "    return any(example['srl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.filter(filter_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicate(example):\n",
    "    predicate = example['lemmas'][example['rank'].index('Предикат')]\n",
    "    return predicate\n",
    "\n",
    "def register_predicates(ds):\n",
    "    predicates_count = {}\n",
    "    def handle_predicate(example):\n",
    "        predicate = get_predicate(example)\n",
    "        if predicate not in predicates_count:\n",
    "            predicates_count[predicate] = 1\n",
    "        else:\n",
    "            predicates_count[predicate] += 1\n",
    "        return {'predicate': predicate}\n",
    "\n",
    "    ds.map(handle_predicate)\n",
    "    print(predicates_count)\n",
    "    return predicates_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "predicates_count = register_predicates(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_predicates = [pred for (pred, cnt) in predicates_count.items() if cnt >= 10 and pred in role_mapping.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fn(example):\n",
    "    predicate = get_predicate(example)\n",
    "    return predicate in good_predicates and all([role in role_mapping[predicate] for role in example['srl'] if role is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "    features: \u001b[1m[\u001b[0m\u001b[32m'doc_id'\u001b[0m, \u001b[32m'sent_idx'\u001b[0m, \u001b[32m'tokens'\u001b[0m, \u001b[32m'lemmas'\u001b[0m, \u001b[32m'rank'\u001b[0m, \u001b[32m'srl'\u001b[0m, \u001b[32m'text_fixed'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    num_rows: \u001b[1;36m0\u001b[0m\n",
       "\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].filter(filter_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_verbs(text):\n",
    "    verbs, forms = list(), list()\n",
    "    for tok in model(text):\n",
    "        if tok.pos_ == \"VERB\":\n",
    "            verbs.append(tok.lemma_)\n",
    "            forms.append(tok.text)\n",
    "    return verbs, forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets as ds\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_examples(ds, n_examples=5):\n",
    "    examples = {}\n",
    "    def pick_as_example(example):\n",
    "        predicate = get_predicate(example)\n",
    "        if predicate not in examples:\n",
    "            examples[predicate] = []\n",
    "        exclude = False\n",
    "        if len(examples[predicate]) < n_examples:\n",
    "            examples[predicate].append(example)\n",
    "            exclude = True\n",
    "        return {'exclude': exclude}\n",
    "\n",
    "    pick_as_example(ds[0])\n",
    "    new_ds = ds.map(pick_as_example)\n",
    "    new_ds = new_ds.filter(lambda example: not example['exclude'])\n",
    "    return new_ds, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21716/21716 [00:02<00:00, 9733.71 examples/s]\n",
      "Filter: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21716/21716 [00:01<00:00, 20024.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data = data.shuffle(seed=42)\n",
    "data, examples_for_predicates = extract_examples(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "class SemanticRole(BaseModel):\n",
    "    short_reasoning: Annotated[str, Field(min_length=16, max_length=64)]\n",
    "    arg_role: Literal[\"Cause\", \"Experiencer\", \"Causator\", \"Deliberative\", \"Instrument\", \"Object\", \"Not-Applicable\"]\n",
    "    arg_phrase_or_clause: Annotated[str, Field(min_length=1, max_length=64)]\n",
    "    arg_main_indicative_word: Annotated[str, Field(min_length=1, max_length=32)]\n",
    "\n",
    "class SemanticRoleMarkup(BaseModel):\n",
    "    roles: List[SemanticRole]\n",
    "    model_config = {\n",
    "        \"title\": \"SemanticRoleMarkup\",\n",
    "        \"description\": \"Semantic Role Markup\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt_for_example_vllm(example):\n",
    "    example_predicate = get_predicate(example)\n",
    "    rule_set = role_mapping[example_predicate]\n",
    "    rule_set = json.dumps(rule_set, ensure_ascii=False, indent=4)\n",
    "    example_set = examples_for_predicates[example_predicate]\n",
    "\n",
    "    prompt = [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': f'''\n",
    "You are a native russian linguist specializing in semantic role labelling. \\\n",
    "You must find the verb \"{example_predicate}\" and its arguments in the sentence \\\n",
    "and determine the semantic roles of the arguments from one of the following:\n",
    "```json{rule_set}```, or assign the role 'Not-Applicable' if none of the listed roles fit. '''\n",
    "        }\n",
    "    ]\n",
    "    examples = \"\"\n",
    "    for ex in example_set:\n",
    "        examples += f\"Example Text:\\n{ex['text_fixed']}\\n\"\n",
    "\n",
    "        semantic_roles = \"\"\n",
    "        for (word, role) in zip(ex['lemmas'], ex['srl']):\n",
    "            if role is not None:\n",
    "                semantic_roles += f'{word}#{role}\\n'\n",
    "        examples += f\"Example Semantic Roles:\\n{semantic_roles}\\n\\n\"\n",
    "\n",
    "    inputs = f\"\"\"\n",
    "Given a series of few-shot examples, please predict semantic roles in a target example.\n",
    "Here are the few-shot examples:\n",
    "{examples}\n",
    "\n",
    "Here is the target sentence:\n",
    "{example['text_fixed']}\n",
    "\n",
    "Instructions:\n",
    "- Do not mark semantic roles for implied, implicit or otherwise not presented arguments\n",
    "- Reason out loud (concisely) before answering\n",
    "- Predict both argument phrase (or clause) and a main indicative word of such phrase\n",
    "- Some arguments may not have a phrase and will be represented by a single word. In this case use it as both argument phrase and main indicative word\n",
    "\n",
    "Important: If there are no semantic roles for any argument that you can extract - reply with a ONLY ONE SINGLE argument markup that will have a role \"Not-Applicable\".\n",
    "\"\"\".strip()\n",
    "\n",
    "    \n",
    "\n",
    "    prompt.append({\n",
    "        'role': 'user',\n",
    "        'content': inputs\n",
    "    })\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a native russian linguist specializing in semantic role labelling. You must find the verb \"возмущать\" and its arguments in the sentence and determine the semantic roles of the arguments from one of the following:\n",
      "```json[\n",
      "    \"говорящий - субъект психологического состояния\",\n",
      "    \"субъект психологического состояния\",\n",
      "    \"причина\",\n",
      "    \"содержание высказывания\"\n",
      "]```, or assign the role 'Not-Applicable' if none of the listed roles fit.  Given a series of few-shot examples, please predict semantic roles in a target example.\n",
      "Here are the few-shot examples:\n",
      "Example Text:\n",
      "Хотя бы подумали о пустой трате средств , возмущался Данилов . . .\n",
      "Example Semantic Roles:\n",
      "подумать#содержание высказывания\n",
      "данилов#говорящий - субъект психологического состояния\n",
      "\n",
      "\n",
      "Example Text:\n",
      "Как обыватель я имею возможность либо возмущаться , либо , простите , глотать слюньки , читая , как из Москвы в Питер привозили « сливки » нашей интеллигенции для того , чтобы они , то есть « сливки » , могли в костюмах эпохи героев « Дяди Вани » , взятых в прокат на « Ленфильме » , кушать на природе рябчиков , пухлярок , запивая это французским коньяком . . .\n",
      "Example Semantic Roles:\n",
      "я#говорящий - субъект психологического состояния\n",
      "читать#причина\n",
      "\n",
      "\n",
      "Example Text:\n",
      "Мать возмущалась , устраивала сцены и требовала забрать от нее « этого несчастного ребенка » .\n",
      "Example Semantic Roles:\n",
      "мать#говорящий - субъект психологического состояния\n",
      "\n",
      "\n",
      "Example Text:\n",
      "Его искренне возмущало -- с какой стати он , многое создавший , имеющий опыт , заслуги , положение , должен теперь , под старость , уступить свое место какому - нибудь безвестному юнцу вроде Лобанова .\n",
      "Example Semantic Roles:\n",
      "он#субъект психологического состояния\n",
      "должен#причина\n",
      "\n",
      "\n",
      "Example Text:\n",
      "Кто - то придумал не в добрый час приспособить » Зори « к русской действительности , -- возмущалась Крупская .\n",
      "Example Semantic Roles:\n",
      "крупская#говорящий - субъект психологического состояния\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here is the target sentence:\n",
      "Текли они от страха и отчаяния , и поэтому юнкер все время возмущался , тщетно пытаясь выдать их за слезы оскорбленной гордости .\n",
      "\n",
      "Instructions:\n",
      "- Do not mark semantic roles for implied, implicit or otherwise not presented arguments\n",
      "- Reason out loud (concisely) before answering\n",
      "- Predict both argument phrase (or clause) and a main indicative word of such phrase\n",
      "- Some arguments may not have a phrase and will be represented by a single word. In this case use it as both argument phrase and main indicative word\n",
      "\n",
      "Important: If there are no semantic roles for any argument that you can extract - reply with a ONLY ONE SINGLE argument markup that will have a role \"Not-Applicable\".\n"
     ]
    }
   ],
   "source": [
    "random_example = data[0]\n",
    "prompt = make_prompt_for_example_vllm(random_example)\n",
    "print(prompt[0]['content'], prompt[1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def make_request_ollama(model, example):\n",
    "    messages = make_prompt_for_example_vllm(example)\n",
    "    client = ollama.Client(\n",
    "      host='http://localhost:11435'\n",
    "    )\n",
    "    try:\n",
    "        stream = client.chat(model=model, messages=messages, stream=True)\n",
    "\n",
    "        response = \"\"\n",
    "        for chunk in stream:\n",
    "            print(chunk['message']['content'], end='', flush=True)\n",
    "            response += chunk['message']['content']\n",
    "\n",
    "        return {\n",
    "            'llm-response': response\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'llm-response': f\"ERROR + {e}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, I'm trying to figure out the semantic roles in the target sentence using the examples provided. The task is to identify the verb \"возмущать\" and its arguments, then assign the appropriate roles from the given list.\n",
      "\n",
      "First, let's look at the target sentence:\n",
      "\"Текли они от страха и отчаяния , и поэтому юнкер все время возмущался , тщетно пытаясь выдать их за слезы оскорбленной гордости .\"\n",
      "\n",
      "The verb here is \"возмущался,\" which means \"was upset\" or \"protested.\" The subject of this verb is \"юнкер,\" a noun referring to a cadet. So, the main argument is \"юнкер.\"\n",
      "\n",
      "Looking at the examples provided, when the verb is \"возмущать,\" the subject (like \"Данилов,\" \"я,\" \"мать,\" etc.) is usually assigned the role of \"говорящий - субъект психологического состояния.\" This makes sense because they are expressing their emotional state through protest or upset.\n",
      "\n",
      "In this case, \"юнкер\" is the one who is upset. There's no other explicit argument in the sentence that fits into the roles like \"причина\" (cause) or \"содержание высказывания\" (content of speech). The reasons for his upset are given in the context (\"от страха и отчаяния\"), but those aren't direct arguments of the verb \"возмущался.\" Instead, they provide background.\n",
      "\n",
      "So, based on the examples and structure, I should assign \"юнкер\" the role of \"говорящий - субъект психологического состояния.\"\n",
      "</think>\n",
      "\n",
      "The subject of the verb \"возмущался\" is \"юнкер,\" who is expressing his emotional state. \n",
      "\n",
      "юнкер#говорящий - субъект психологического состояния"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'llm-response'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32mthink\u001b[0m\u001b[32m>\\nAlright, I\\'m trying to figure out the semantic roles in the target sentence using the examples provided. The task is to identify the verb \"возмущать\" and its arguments, then assign the appropriate roles from the given list.\\n\\nFirst, let\\'s look at the target sentence:\\n\"Текли они от страха и отчаяния , и поэтому юнкер все время возмущался , тщетно пытаясь выдать их за слезы оскорбленной гордости .\"\\n\\nThe verb here is \"возмущался,\" which means \"was upset\" or \"protested.\" The subject of this verb is \"юнкер,\" a noun referring to a cadet. So, the main argument is \"юнкер.\"\\n\\nLooking at the examples provided, when the verb is \"возмущать,\" the subject \u001b[0m\u001b[32m(\u001b[0m\u001b[32mlike \"Данилов,\" \"я,\" \"мать,\" etc.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is usually assigned the role of \"говорящий - субъект психологического состояния.\" This makes sense because they are expressing their emotional state through protest or upset.\\n\\nIn this case, \"юнкер\" is the one who is upset. There\\'s no other explicit argument in the sentence that fits into the roles like \"причина\" \u001b[0m\u001b[32m(\u001b[0m\u001b[32mcause\u001b[0m\u001b[32m)\u001b[0m\u001b[32m or \"содержание высказывания\" \u001b[0m\u001b[32m(\u001b[0m\u001b[32mcontent of speech\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The reasons for his upset are given in the context \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\"от страха и отчаяния\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, but those aren\\'t direct arguments of the verb \"возмущался.\" Instead, they provide background.\\n\\nSo, based on the examples and structure, I should assign \"юнкер\" the role of \"говорящий - субъект психологического состояния.\"\\n</think\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\n\\nThe subject of the verb \"возмущался\" is \"юнкер,\" who is expressing his emotional state. \\n\\nюнкер#говорящий - субъект психологического состояния'\u001b[0m\n",
       "\u001b[1m}\u001b[0m"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_request_ollama('deepseek-r1:32b', random_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def map_to_words_info(example):\n",
    "    values = zip(example['tokens'],\n",
    "               example['lemmas'],\n",
    "               example['rank'],\n",
    "               example['srl'])\n",
    "    return {'words': list(values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'words'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'Текли'\u001b[0m, \u001b[32m'течь'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'они'\u001b[0m, \u001b[32m'они'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'от'\u001b[0m, \u001b[32m'от'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'страха'\u001b[0m, \u001b[32m'страх'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'и'\u001b[0m, \u001b[32m'и'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'отчаяния'\u001b[0m, \u001b[32m'отчаяние'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m','\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'и'\u001b[0m, \u001b[32m'и'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'поэтому'\u001b[0m, \u001b[32m'поэтому'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'юнкер'\u001b[0m, \u001b[32m'юнкер'\u001b[0m, \u001b[32m'Субъект'\u001b[0m, \u001b[32m'говорящий - субъект психологического состояния'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'все'\u001b[0m, \u001b[32m'весь'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'время'\u001b[0m, \u001b[32m'время'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'возмущался'\u001b[0m, \u001b[32m'возмущать'\u001b[0m, \u001b[32m'Предикат'\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m','\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'тщетно'\u001b[0m, \u001b[32m'тщетно'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'пытаясь'\u001b[0m, \u001b[32m'пытаться'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'выдать'\u001b[0m, \u001b[32m'выдавать'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'их'\u001b[0m, \u001b[32m'они'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'за'\u001b[0m, \u001b[32m'за'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'слезы'\u001b[0m, \u001b[32m'слеза'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'оскорбленной'\u001b[0m, \u001b[32m'оскорблять'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'гордости'\u001b[0m, \u001b[32m'гордость'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1m(\u001b[0m\u001b[32m'.'\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m, \u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_to_words_info(random_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=16): 100%|██████████| 7602/7602 [09:45<00:00, 12.98 examples/s]  \n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "data = data.map(make_request_openai, num_proc=16)\n",
    "t2 = time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_roles_vllm(example):\n",
    "    if example['llm-response'] is not None:\n",
    "        roles = []\n",
    "        try:\n",
    "            response = json.loads(example['llm-response'])\n",
    "            for item in response['roles']:\n",
    "                #print(item)\n",
    "                role = item['arg_role']\n",
    "                content = item['arg_phrase_or_clause']\n",
    "                if 'Not-Applicable' not in {role, content}:\n",
    "                    roles.append({\n",
    "                        'role': role.strip(),\n",
    "                        'argument': content\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return {'roles': roles}\n",
    "    else:\n",
    "        return {'roles': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_roles_openai(example):\n",
    "    if example['llm-response'] is not None and '- No-Roles#No-Roles' not in example['llm-response'] and \"ERROR +\" not in example['llm-response']:\n",
    "        roles = []\n",
    "        for item in example['llm-response'].split(\"\\n\"):\n",
    "            role = item.split(\"#\")[-1]\n",
    "            argument = item.replace(f\"#{role}\", \"\")\n",
    "            argument = argument.replace(\"- \", \"\")\n",
    "            roles.append({\n",
    "                'argument': argument,\n",
    "                'role': role\n",
    "            })\n",
    "        return {'roles': roles}\n",
    "    else:\n",
    "        return {'roles': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7602/7602 [00:00<00:00, 28534.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data = data.map(fix_roles_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def create_roles_dataframe(examples: List[Dict]) -> pd.DataFrame:\n",
    "    # List to store all rows\n",
    "    rows = []\n",
    "    \n",
    "    for example in tqdm(examples):\n",
    "        # Get roles list from the example\n",
    "        roles = example.get('roles', [])\n",
    "\n",
    "        # For each role in the example (except No-Roles)\n",
    "        for role_dict in roles:\n",
    "            if role_dict['role'] == 'No-Roles':\n",
    "                continue\n",
    "                \n",
    "            # Create a new row with all metadata and role information\n",
    "            row = {\n",
    "                'group': example.get('group'),\n",
    "                'global_id': example.get('global_id'),\n",
    "                'date': example.get('date'),\n",
    "                'text': example.get('text_fixed'),\n",
    "                'predicate': example.get('predicate', [''])[0],  # Take first predicate\n",
    "                'lemma': example.get('lemma', [''])[0],  # Take first lemma\n",
    "                'predicate_group': example.get('predicate_group'),\n",
    "                'llm_response': example.get('llm-response'),\n",
    "                'has_negation': example.get('has_negation'),\n",
    "                'argument': role_dict.get('argument'),\n",
    "                'role': role_dict.get('role')\n",
    "            }\n",
    "            rows.append(row)\n",
    "    \n",
    "    # Create DataFrame from all rows\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3489/3489 [00:00<00:00, 7282.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "Empty DataFrame\n",
       "Columns: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "Index: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_roles_dataframe(data['train'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in &lt;module&gt;:1                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 <span style=\"font-weight: bold; text-decoration: underline\">data[</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">'train'</span><span style=\"font-weight: bold; text-decoration: underline\">][</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">0</span><span style=\"font-weight: bold; text-decoration: underline\">][</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">'role'</span><span style=\"font-weight: bold; text-decoration: underline\">]</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in <module>:1                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 \u001b[1;4mdata[\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33mtrain\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4m][\u001b[0m\u001b[1;4;94m0\u001b[0m\u001b[1;4m][\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33mrole\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4m]\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'role'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7602 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7602/7602 [00:00<00:00, 29381.39it/s]\n"
     ]
    }
   ],
   "source": [
    "data_frame = create_roles_dataframe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.drop(['llm_response'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
